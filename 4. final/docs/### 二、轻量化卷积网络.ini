### 二、轻量化卷积网络

在端侧轻量级人脸检测模型中，backbone的选择是至关重要的。它负责提取图像的特征，其性能和效率直接影响整个模型的效果。当前，主流端侧模型通常会优先选用mobilenet这类轻量化架构作为backbone。接下来，我们将详细介绍mobilenet、shufflenet、squeezenet等轻量化卷积网络。

特别说明一下，本次汇报所涉及的三个网络均迭代了多个版本，以mobilenet为例，在2019年之前已发布过三个版本，今年四月又推出了mobilenet v4。这里我们主要聚焦于各个轻量化cnn模型初始版本的创新点。

### 1. MobileNet

MobileNet由Google团队于2017年提出，主要应用于移动和嵌入式视觉领域，如物体检测、细粒度分类、人脸属性分析以及大规模地理定位等场景。它基于一种流线型架构，采用深度可分离卷积构建轻量级深层神经网络。

MobileNet的核心创新在于深度可分离卷积，它将传统卷积操作分解为深度卷积（Depthwise Conv）和逐点卷积（Pointwise Conv）两部分。以VGG为例，普通网络是直接进行Conv、BN、ReLU操作，而MobileNet基础模块先执行Depthwise Conv、BN、ReLU操作，再进行Pointwise Conv、BN、ReLU操作。

深度可分离卷积的优势明显，在相同权值参数数量下，相较于标准卷积，其计算量大幅减少。深度卷积中，一个卷积核仅处理一个通道，实现空间信息的提取；逐点卷积则负责将深度卷积得到的特征图进行通道信息融合，确保每个输出特征图包含所有输入特征图的信息。例如，对于一张$D_F×D_F×M$的方形特征图，标准卷积计算量为$D_K·D_K·M·N·D_F·D_F$，而深度可分离卷积计算量为$D_K·D_K·M·D_F·D_F+M·N·D_F·D_F$，两者计算量相除可得深度可分离卷积相对标准卷积减少的计算量比例。若引入超参数α（Width Multiplier）和ρ（Resolution Multiplier），计算量可进一步缩减。

然而，MobileNet也并非完美。ReLU激活函数在低维特征图上使用时，可能破坏特征，且当ReLU输出为0时会导致特征退化，虽可通过残差连接缓解，但仍是改进方向。

### 2. ShuffleNet

ShuffleNet由Face++团队（旷世科技）于2017年提出，旨在将网络架构优化以适配移动设备。与MobileNet等轻量化网络不同，ShuffleNet的独特之处在于采用通道重排（channel shuffle）等技术，提升计算资源利用率，优化信息流通。

ShuffleNet主要由ShuffleNet块（ShuffleNet Unit）逐层组合而成。每个ShuffleNet块包含分组卷积（Group Conv）、通道重排和逐点卷积三个关键步骤。分组卷积将卷积操作分组，减少参数量和计算量，但会引发信息流通不畅的问题；通道重排巧妙地重新排列特征通道，使不同通道间能够交互信息，解决分组卷积的弊端；逐点卷积则整合通道信息。

ShuffleNet的创新点在于结合group convolution和channel shuffle，其中channel shuffle原创性地解决了group convolution导致的信息孤岛问题。在网络拓扑结构上，ShuffleNet借鉴ResNet思想，与采用VGG思想的MobileNet形成差异。

不过，ShuffleNet也存在一些问题。Channel Shuffle操作较为耗时，影响实际运行速度，且其规则人为设定，具有一定人工设计特征的局限性。

### 3. SqueezeNet

SqueezeNet由伯克利和斯坦福的研究人员合作发表于2017年的ICLR会议。与传统卷积神经网络相比，它在参数量和计算量上显著降低，同时保持较高准确率，尤其适合资源受限设备部署。

SqueezeNet的设计关键有两点。一是广泛运用1×1卷积核，有效减少参数量和计算量；二是引入“squeeze - and - excitation”模块（Fire Module）提升网络表达能力。Fire Module由Squeeze和Extract两部分组成，Squeeze部分通过1×1卷积“压缩”特征图通道数，Extract部分则用1×1和3×3卷积提升通道数并拼接结果。使用Fire Module时，需确保Squeeze部分1×1卷积个数小于Extract部分卷积核个数之和，以控制3×3卷积输入通道数。SqueezeNet的网络结构类似VGG，通过堆叠Fire Module构建。

SqueezeNet采用三项策略压缩模型：以1×1卷积替代3×3卷积；减少3×3卷积输入通道数；延迟降采样操作，为卷积提供更大激活图，保留更多信息，提升分类准确率。但SqueezeNet也有缺点，其通过加深网络减少参数量，可能导致测试阶段耗时增加，在嵌入式场景应用时需谨慎考虑。

### 4. 网络对比

下面从多个维度对这三种轻量化卷积网络进行对比分析。

#### 1. 模型参数量与计算量
 - MobileNet通过深度可分离卷积大幅削减参数量和计算量，相比标准卷积优势明显，计算量公式为$D_K·D_K·M·D_F·D_F+M·N·D_F·D_F$（引入超参数后可进一步缩减）。
 - ShuffleNet借助分组卷积和通道重排进一步降低参数量，特别是在1×1卷积层，通过替换操作减少大量权值参数，提升效率。
 - SqueezeNet凭借1×1卷积替代和减少3×3卷积通道数等策略，参数量降至极低，如仅为AlexNet的1/50，但深层网络结构可能增加测试耗时。

#### 2. 网络结构特点
 - MobileNet基于深度可分离卷积构建，通过深度卷积和逐点卷积协同工作，下采样由深度卷积步长调整实现，无需传统池化层。
 - ShuffleNet围绕分组卷积、通道重排和逐点卷积构建ShuffleNet块，借鉴ResNet思想，根据不同情况（如卷积步长为2时）调整shortcut路径操作。
 - SqueezeNet以Fire Module为基础堆叠而成，Fire Module内部分为Squeeze和Expand两部分，结构设计参考VGG，部分层后使用max - pooling。

#### 3. 信息处理方式
 - MobileNet的深度卷积使不同通道信息分离，逐点卷积负责融合，确保输出特征图包含完整输入信息。
 - ShuffleNet通过通道重排解决分组卷积的信息阻隔问题，促进不同组间信息交流。
 - SqueezeNet在Fire Module中，先由1×1卷积“压缩”通道数，再用1×1和3×3卷积提升并拼接，实现信息整合与表达能力提升。

#### 4. 模型性能表现
 - MobileNet在ImageNet数据集上TOP - 1 Accuracy达70.6%，高于GoogLeNet，计算时间仅为其三分之一左右，与VGG - 16相比，计算量和参数量优势显著。
 - ShuffleNet的TOP - 1 Accuracy为67.4%（1x, g = 3）或67.6%（1x, g = 8），在相同Complexity（MFLOPs）下，效率优于MobileNet。
 - SqueezeNet的TOP - 1 Accuracy为57.5%、TOP - 5 Accuracy为80.3%（与AlexNet相当），模型经Deep Compression后可至0.47MB（实际4.8MB），在低参数量下保持一定准确率。

#### 5. 应用场景特点
 - MobileNet性能平衡，适用于多种移动和嵌入式视觉任务，如物体检测与人脸属性分析。
 - ShuffleNet在实时性要求高且资源受限场景有潜力，但需权衡Channel Shuffle耗时问题。
 - SqueezeNet适合对模型大小严格受限、准确率要求不特别高的资源受限设备，如简单图像分类或检测任务的嵌入式应用。

通过以上对比，我们能清晰看到这三种轻量化卷积网络各有千秋。在实际端侧轻量级人脸检测模型构建中，应根据具体需求和场景特点，合理选择合适的网络作为backbone，以实现最佳性能与资源利用的平衡。