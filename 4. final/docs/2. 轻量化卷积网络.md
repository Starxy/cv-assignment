# 轻量化CNN

## 前言

> https://cloud.tencent.com/developer/article/1451558

自 2012 年 AlexNet 以来，卷积神经网络（简称 CNN）在图像分类、图像分割、目标检测等领域获得广泛应用。随着性能要求越来越高，AlexNet 已经无法满足大家的需求，于是乎各路大牛纷纷提出性能更优越的 CNN 网络，如 VGG、GoogLeNet、ResNet、DenseNet 等。由于神经网络的性质，为了获得更好的性能，网络层数不断增加，从 7 层 AlexNet 到 16 层 VGG，再从 16 层 VGG 到 GoogLeNet 的 22 层，再到 152 层 ResNet，更有上千层的 ResNet 和 DenseNet。虽然网络性能得到了提高，但随之而来的就是效率问题。

效率问题主要是模型的存储问题和模型进行预测的速度问题（以下简称速度问题）

第一，存储问题。数百层网络有着大量的权值参数，保存大量权值参数对设备的内存要求很高；第二，速度问题。在实际应用中，往往是毫秒级别，为了达到实际应用标准，要么提高处理器性能（看英特尔的提高速度就知道了，这点暂时不指望），要么就减少计算量。只有解决 CNN 效率问题，才能让 CNN 走出实验室，更广泛的应用于移动端。对于效率问题，通常的方法是进行模型压缩（Model Compression），即在已经训练好的模型上进行压缩，使得网络携带更少的网络参数，从而解决内存问题，同时可以解决速度问题。

相比于在已经训练好的模型上进行处理，轻量化模型模型设计则是另辟蹊径。轻量化模型设计主要思想在于设计更高效的「网络计算方式」（主要针对卷积方式），从而使网络参数减少的同时，不损失网络性能。

本文就近年提出的四个轻量化模型进行学习和对比，四个模型分别是：MobileNet、ShuffleNet、SqueezeNet、Xception。

## mobilenet

另外一个非常有名的轻量化移动端网络是 MobileNet，它是专用于移动和嵌入式视觉应用的卷积神经网络，是基于一个流线型的架构，使用深度可分离的卷积来构建轻量级的深层神经网络。 MobileNet 凭借其优秀的性能，广泛应用于各种场景中，包括物体检测、细粒度分类、人脸属性和大规模地理定位。

MobileNet有 V1 到 V3 不同的版本，也逐步做了一些优化和效果提升，下面我们来分别看看它的细节。

6.1 MobileNet核心思想
MobileNet V1 的核心是将卷积拆分成 Depthwise Conv 和 Pointwise Conv 两部分，我们来对比一下普通网络和MobileNet的基础模块

普通网络（以VGG为例） ：
3
×
3
 Conv BN ReLU
Mobilenet基础模块：
3
×
3
 Depthwise Conv BN ReLU 和 
1
×
1
 Pointwise Conv BN ReLU
MobileNet; MobileNet 基础模块
MobileNet; MobileNet 基础模块
6.2 MobileNet缺点
① ReLU激活函数用在低维特征图上，会破坏特征。
② ReLU输出为0时导致特征退化。用残差连接可以缓解这一问题。
---

  MobileNet由Google于2017年提出，主要用于在移动设备等资源受限的环境中进行图像分类和目标检测等任务。MobileNet的特点在于，通过使用深度可分离卷积和全局平均池化等技术，大幅减少了网络的参数数量和计算量，从而在保证模型精度的前提下，可以在移动设备等低功耗场景下高效地进行图像识别任务。

  深度可分离卷积将传统卷积操作分成深度卷积和逐点卷积两步，分别处理空间信息和通道信息，从而减少了参数数量和计算量。线性整流单元（ReLU）则可以增强网络的非线性表达能力。
 MobileNet中另一个重要的技术是全局平均池化，它可以将整个特征图转化为一个数，从而减少了参数数量和计算量。同时，全局平均池化也可以降低过拟合的风险，提高模型的泛化能力。
MobileNet 由 Google 团队提出，发表于 CVPR-2017，论文标题：

《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications》

命名：

MobileNet 的命名是从它的应用场景考虑的，顾名思义就是能够在移动端使用的网络模型。

创新点：

1. 采用名为 depth-wise separable convolution 的卷积方式代替传统卷积方式，以达到减少网络权值参数的目的。

通过采用 depth-wise convolution 的卷积方式，达到：1. 减少参数数量 2. 提升运算速度。（这两点是要区别开的，参数少的不一定运算速度快！还要看计算方式！）

depth-wise convolution 不是 MobileNet 提出来的，也是借鉴，文中给的参考文献是 2014 年的博士论文——《L. Sifre. Rigid-motion scattering for image classification. hD thesis, Ph. D. thesis, 2014》

depth-wise convolution 和 group convolution 是类似的，depth-wise convolution 是一个卷积核负责一部分 feature map，每个 feature map 只被一个卷积核卷积；group convolution 是一组卷积核负责一组 feature map，每组 feature map 只被一组卷积核卷积。Depth-wise convolution 可以看成是特殊的 group convolution，即每一个通道是一组。

MobileNets 精华在于卷积方式——depth-wise separable convolution；采用 depth-wise separable convolution，会涉及两个超参：Width Multiplier 和 Resolution Multiplier 这两个超参只是方便于设置要网络要设计为多小，方便于量化模型大小。

MobileNet 将标准卷积分成两步：

第一步 Depth-wise convolution, 即逐通道的卷积，一个卷积核负责一个通道，一个通道只被一个卷积核「滤波」；
第二步，Pointwise convolution，将 depth-wise convolution 得到的 feature map 再「串」起来，注意这个「串」是很重要的。「串」作何解？为什么还需要 pointwise convolution？作者说：However it only filters input channels, it does not combine them to create new features. Soan additional layer that computes a linear combination ofthe output of depth-wise convolution via 1 × 1 convolutionis needed in order to generate these new features。
从另外一个角度考虑，其实就是：输出的每一个 feature map 要包含输入层所有 feature map 的信息。然而仅采用 depth-wise convolution，是没办法做到这点，因此需要 pointwise convolution 的辅助。

「输出的每一个 feature map 要包含输入层所有 feature map 的信息」这个是所有采用 depth-wise convolution 操作的网络都要去解决的问题，ShuffleNet 中的命名就和这个有关！详细请看 2.3。

Standard convolution、depth-wise convolution 和 pointwise convolution 示意图如下：

 



其中输入的 feature map 有 M 个，输出的 feature map 有 N 个。

对 Standard convolution 而言，是采用 N 个大小为 DK*DK 的卷积核进行操作（注意卷积核大小是 DK*DK, DK*DK*M 是具体运算时一个卷积核的大小！）。

而 depth-wise convolution + pointwise convolution 需要的卷积核呢？

Depth-wise convolution ：一个卷积核负责一个通道，一个通道只被一个卷积核卷积；则这里有 M 个 DK*DK 的卷积核； 

Pointwise convolution：为了达到输出 N 个 feature map 的操作，所以采用 N 个 1*1 的卷积核进行卷积，这里的卷积方式和传统的卷积方式是一样的，只不过采用了 1*1 的卷积核；其目的就是让新的每一个 feature map 包含有上一层各个 feature map 的信息！在此理解为将 depth-wise convolution 的输出进行「串」起来。

下面举例讲解 Standard convolution、depth-wise convolution 和 pointwise convolution。

假设输入的 feature map 是两个 5*5 的，即 5*5*2；输出 feature map 数量为 3，大小是 3*3（因为这里采用 3*3 卷积核）即 3*3*3。

标准卷积是将一个卷积核（3*3）复制 M 份（M=2）, 让二维的卷积核（面包片）拓展到与输入 feature map 一样的面包块形状。

Standard 过程如下图，X 表示卷积，+表示对应像素点相加，可以看到对于 O1 来说，其与输入的每一个 feature map 都「发生关系」，包含输入的各个 feature map 的信息。



Depth-wise 过程如下图，可以看到 depth-wise convolution 得出的两个 feature map——fd1 和 fd2 分别只与 i1 和 i2「发生关系」，这就导致违背上面所承认的观点「输出的每一个 feature map 要包含输入层所有 feature map 的信息」，因而要引入 pointwise convolution。



那么计算量减少了多少呢？通过如下公式计算： 

 



其中 DK 为标准卷积核大小，M 是输入 feature map 通道数，DF 为输入 feature map 大小，N 是输出 feature map 大小。本例中，DK=3，M=2，DF=5，N=3，参数的减少量主要就与卷积核大小 DK 有关。在本文 MobileNet 的卷积核采用 DK=3，则大约减少了 8~9 倍计算量。

看看 MobileNet 的网络结构，MobileNet 共 28 层，可以发现这里下采样的方式没有采用池化层，而是利用 depth-wise convolution 的时候将步长设置为 2，达到下采样的目的。



1.0 MobileNet-224 与 GoogLeNet 及 VGG-16 的对比：



可以发现，相较于 GoogLeNet，虽然参数差不多，都是一个量级的，但是在运算量上却小于 GoogLeNet 一个量级，这就得益于 depth-wise convolution！

MobileNet 小结：

1. 核心思想是采用 depth-wise convolution 操作，在相同的权值参数数量的情况下，相较于 standard convolution 操作，可以减少数倍的计算量，从而达到提升网络运算速度的目的。
2. depth-wise convolution 的思想非首创，借鉴于 2014 年一篇博士论文：《L. Sifre. Rigid-motion scattering for image classification. hD thesis, Ph. D. thesis, 2014》
3. 采用 depth-wise convolution 会有一个问题，就是导致「信息流通不畅」，即输出的 feature map 仅包含输入的 feature map 的一部分，在这里，MobileNet 采用了 point-wise convolution 解决这个问题。在后来，ShuffleNet 采用同样的思想对网络进行改进，只不过把 point-wise convolution 换成了 channel shuffle，然后给网络美其名曰 ShuffleNet，欲知后事如何，请看 2.3 ShuffleNet
---

1. MobileNet-V1
文章标题：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

作者单位：Google Inc.

网络精度：TOP-1 Accuracy 70.6%

1.1 核心思路
利用 Xception 提出的深度可分离卷积替换传统的标准卷积，大幅减少了模型参数量和计算量，对于相同分辨率的方形图像，深度可分离卷积的计算量仅为标准卷积的 1 N + 1 D K 2 \frac{1}{N}+\frac{1}{D_K^2} 
N
1
​
 + 
D 
K
2
​
 
1
​
  ；

给出两个超参数 Width Multiplier 和 Resolution Multiplier，分别记为 α αα 和 ρ ρρ ，进一步缩小模型以用于更为特殊的场合。

1.2 详解
1. Depthwise Separable Convolution（深度可分离卷积）

深度可分离卷积的思想灵感来自于一篇博士论文《Rigid-motion scattering for image classification》，而后在 Xception 中被提出并使用（并非 MobileNet V1 首创，但都是Google所提）。

深度可分离卷积分为深度卷积（depthwise convolutions）和逐点卷积（pointwise convolutions）两部分，深度卷积导致不同通道之间的信息无法进行交互，所以设置了逐点卷积让深度卷积后的特征图进行线性的结合，也就是实现通道间的信息融合。

在这里插入图片描述

2. 标准卷积和深度可分离卷积的计算量比较

若假设 D K D_KD 
K
​
  是卷积核的大小，M MM 是输入通道数，N NN 是输出通道数。对于一张 D F × D F × M D_F×D_F×MD 
F
​
 ×D 
F
​
 ×M 的方形特征图，标准卷积的计算量为：D K ⋅ D K ⋅ M ⋅ N ⋅ D F ⋅ D F D_K·D_K·M·N·D_F·D_FD 
K
​
 ⋅D 
K
​
 ⋅M⋅N⋅D 
F
​
 ⋅D 
F
​
 ，而深度可分离卷积的计算量为：D K ⋅ D K ⋅ M ⋅ D F ⋅ D F + M ⋅ N ⋅ D F ⋅ D F D_K·D_K·M·D_F·D_F+M·N·D_F·D_FD 
K
​
 ⋅D 
K
​
 ⋅M⋅D 
F
​
 ⋅D 
F
​
 +M⋅N⋅D 
F
​
 ⋅D 
F
​
  。

其中， D K ⋅ D K ⋅ M ⋅ D F ⋅ D F D_K·D_K·M·D_F·D_FD 
K
​
 ⋅D 
K
​
 ⋅M⋅D 
F
​
 ⋅D 
F
​
  对应于深度卷积的计算量，M ⋅ N ⋅ D F ⋅ D F M·N·D_F·D_FM⋅N⋅D 
F
​
 ⋅D 
F
​
  对应于逐点卷积的计算量。

两者计算量相除可以得到：
D K ⋅ D K ⋅ M ⋅ D F ⋅ D F + M ⋅ N ⋅ D F ⋅ D F D K ⋅ D K ⋅ M ⋅ N ⋅ D F ⋅ D F = 1 N + 1 D K 2 \frac{D_K·D_K·M·D_F·D_F+M·N·D_F·D_F}{D_K·D_K·M·N·D_F·D_F }=\frac{1}{N}+\frac{1}{D_K^2}
D 
K
​
 ⋅D 
K
​
 ⋅M⋅N⋅D 
F
​
 ⋅D 
F
​
 
D 
K
​
 ⋅D 
K
​
 ⋅M⋅D 
F
​
 ⋅D 
F
​
 +M⋅N⋅D 
F
​
 ⋅D 
F
​
 
​
 = 
N
1
​
 + 
D 
K
2
​
 
1
​
 

其中， 1 D K 2 \frac{1}{D_K^2} 
D 
K
2
​
 
1
​
  便是深度可分离卷积相对于标准卷积所减少的计算量比例。

若是进一步引入两个超参数 α αα 和 ρ ρρ，则计算量可以进一步缩减至 D K ⋅ D K ⋅ α M ⋅ ρ D F ⋅ ρ D F + α M ⋅ α N ⋅ ρ D F ⋅ ρ D F D_K·D_K·αM·ρD_F·ρD_F+αM·αN·ρD_F·ρD_FD 
K
​
 ⋅D 
K
​
 ⋅αM⋅ρD 
F
​
 ⋅ρD 
F
​
 +αM⋅αN⋅ρD 
F
​
 ⋅ρD 
F
​
 ，此时与标准卷积的计算量比为：

D K ⋅ D K ⋅ α M ⋅ ρ D F ⋅ ρ D F + α M ⋅ α N ⋅ ρ D F ⋅ ρ D F D K ⋅ D K ⋅ M ⋅ N ⋅ D F ⋅ D F = α ρ 2 N + α 2 ρ 2 D K 2 \frac{D_K·D_K·αM·ρD_F·ρD_F+αM·αN·ρD_F·ρD_F}{D_K·D_K·M·N·D_F·D_F} =\frac{αρ^2}{N}+\frac{α^2 ρ^2}{D_K^2}
D 
K
​
 ⋅D 
K
​
 ⋅M⋅N⋅D 
F
​
 ⋅D 
F
​
 
D 
K
​
 ⋅D 
K
​
 ⋅αM⋅ρD 
F
​
 ⋅ρD 
F
​
 +αM⋅αN⋅ρD 
F
​
 ⋅ρD 
F
​
 
​
 = 
N
αρ 
2
 
​
 + 
D 
K
2
​
 
α 
2
 ρ 
2
 
​
 

其中，α αα 和 ρ ρρ 的取值范围为 [0,1]。

3. 网络结构

在这里插入图片描述

计算时间和参数量占比情况：

在这里插入图片描述

可见，MobileNet V1 中逐点卷积的计算时间和参数量都占据了绝大比重，这也是后续 ShuffleNet V1 所提出的一个观点。

4. MobileNet V1的性能表现

在这里插入图片描述

标准的 MobileNet V1 在 ImageNet 数据集上的 TOP-1 Accuracy 为 70.6%，高于 GoogLeNet ，但其计算时间仅为 GoogLeNet 的 1/3 左右。相较于 VGG-16 而言，虽然精度上降低了 0.9%，但在计算时间和参数量上都实现了大幅度的降低。

## shufflenet

  ShuffleNet与MobileNet等轻量化网络不同，ShuffleNet的主要特点在于采用了通道重排等技术，以更高效地利用计算资源和减少信息流量。

  ShuffleNet的主要结构由逐层组合的ShuffleNet块（ShuffleNet Unit）构成。每个ShuffleNet块主要包括分组卷积、通道重排和逐点卷积（pointwise convolution）三个步骤。其中，分组卷积可以将卷积操作分为多个小组进行，减少了参数数量和计算量。通道重排则将特征通道重新排列，使得不同的通道之间可以相互交流，提高了信息流动性。逐点卷积则可以对通道上的信息进行整合。

---

ShuffleNet 是 Face++团队提出的，与 MobileNet 一样，发表于 CVPR-2017，但晚于 MobileNet 两个月才在 arXiv 上公开。论文标题：

《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices》

命名：

一看名字 ShuffleNet，就知道 shuffle 是本文的重点，那么 shuffle 是什么？为什么要进行 shuffle？

shuffle 具体来说是 channel shuffle，是将各部分的 feature map 的 channel 进行有序的打乱，构成新的 feature map，以解决 group convolution 带来的「信息流通不畅」问题。（MobileNet 是用 point-wise convolution 解决的这个问题）

因此可知道 shuffle 不是什么网络都需要用的，是有一个前提，就是采用了 group convolution，才有可能需要 shuffle！！为什么说是有可能呢？因为可以用 point-wise convolution 来解决这个问题。

创新点：

1. 利用 group convolution 和 channel shuffle 这两个操作来设计卷积神经网络模型, 以减少模型使用的参数数量。

其中 group convolutiosn 非原创，而 channel shuffle 是原创。channel shuffle 因 group convolution 而起，正如论文中 3.1 标题： . Channel Shuffle for Group Convolution； 

采用 group convolution 会导致信息流通不当，因此提出 channel shuffle，所以 channel shuffle 是有前提的，使用的话要注意！

对比一下 MobileNet，采用 shuffle 替换掉 1*1 卷积，这样可以减少权值参数，而且是减少大量权值参数，因为在 MobileNet 中，1*1 卷积层有较多的卷积核，并且计算量巨大，MobileNet 每层的参数量和运算量如下图所示：



ShuffleNet 的创新点在于利用了 group convolution 和 channel shuffle，那么有必要看看 group convolution 和 channel shuffle。

Group convolution 

Group convolution 自 Alexnet 就有，当时因为硬件限制而采用分组卷积；之后在 2016 年的 ResNeXt 中，表明采用 group convolution 可获得高效的网络；再有 Xception 和 MobileNet 均采用 depth-wise convolution, 这些都是最近出来的一系列轻量化网络模型。depth-wise convolution 具体操作可见 2.2 MobileNet 里边有简介。

如下图 (a) 所示, 为了提升模型效率，采用 group convolution，但会有一个副作用，即：「outputs from a certain channel are only derived from a small fraction of input channels.」

于是采用 channel shuffle 来改善各组间「信息流通不畅」问题，如下图 (b) 所示。

具体方法为：把各组的 channel 平均分为 g（下图 g=3）份，然后依次序的重新构成 feature map。



Channel shuffle 的操作非常简单，接下来看看 ShuffleNet，ShuffleNet 借鉴了 Resnet 的思想，从基本的 resnet 的 bottleneck unit 逐步演变得到 ShuffleNet 的 bottleneck unit，然后堆叠的使用 ShuffleNet bottleneck unit 获得 ShuffleNet；

下图展示了 ShuffleNet unit 的演化过程 

图 (a)：是一个带有 depth-wise convolution 的 bottleneck unit；
图 (b)：作者在 (a) 的基础上进行变化，对 1*1 conv 换成 1*1 Gconv，并在第一个 1*1 Gconv 之后增加一个 channel shuffle 操作； 
图 (c)： 在旁路增加了 AVG pool，目的是为了减小 feature map 的分辨率；因为分辨率小了，于是乎最后不采用 Add，而是 concat，从而「弥补」了分辨率减小而带来的信息损失。


文中提到两次，对于小型网络，多多使用通道，会比较好。

「this is critical for small networks, as tiny networks usually have an insufficient number of channels to process the information」

所以，以后若涉及小型网络，可考虑如何提升通道使用效率。

至于实验比较，并没有给出模型参数量的大小比较，而是采用了 Complexity (MFLOPs) 指标，在相同的 Complexity (MFLOPs) 下，比较 ShuffleNet 和各个网络，还专门和 MobileNet 进行对比，由于 ShuffleNet 相较于 MobileNet 少了 1*1 卷积层，所以效率大大提高了嘛，贴个对比图随意感受一下好了。



ShuffleNet 小结：

1. 与 MobileNet 一样采用了 depth-wise convolution，但是针对 depth-wise convolution 带来的副作用——「信息流通不畅」，ShuffleNet 采用了一个 channel shuffle 操作来解决。
2. 在网络拓扑方面，ShuffleNet 采用的是 resnet 的思想，而 mobielnet 采用的是 VGG 的思想，2.1 SqueezeNet 也是采用 VGG 的堆叠思想。

---

ShuffleNet 是由旷世科技提出的轻量化CNN网络，论文名称《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices》，目标是改造网络架构使其能应用在移动设备上。

4.1 设计动机
ShuffleNet的动机在于大量的 1 × 1 卷积会耗费很多计算资源，而 Group Conv 难以实现不同分组之间的信息交流；ShuffleNet 的解决方式是：使用 Group Conv 降低参数量；使用Channel Shuffle实现不同组之间的信息交流，进而对ResNet进行改进，可以看作ResNet的压缩版本。
4.2 Group Conv
我们再来看看Group Conv这个结构，它的基本思想是对输入层的不同特征图进行分组，再使用不同的卷积核对不同组的特征图进行卷积，通过分组降低卷积的计算量。
而Depthwise Convolution可以视作Group Conv的一种特殊情形。
假设输入通道为 C i ，输出通道为 C o ，分组数目为 g ，Group Conv的操作如下： 将输入特征图沿着通道分为 g 组，每一组的通道数目为 C i / g 。 使用 g 个不同的卷积核，每一个卷积核的滤波器数量为 C o / g 。 使用这 g 个不同的卷积核，对 g 组特征图分别进行卷积，得到 g 组输出特征图，每一组的通道数为 C o / g 。 将这 g 组的输出特征图结合，得到最终的 C o 通道的输出特征图。
4.3 Channel Shuffle Group Conv 的一个缺点在于不同组之间难以实现通信。一个可能的解决方式是使用 1 × 1 卷积进行通信，但是这样会引入很大的计算量。 文中提出的思路是对 Group Conv 之后的特征图沿着通道维度进行重组，这样信息就可以在不同组之间流转，即 Channel Shuffle，如下图(c)所示。
其实现过程如下： ① 输入特征图通道数目为 g × n ② 将特征图的通道维度reshape为 ( g , n ) ③ 转置为 ( n , g ) ④ 平坦化成 g × n 个通道
4.4 ShuffleNet基础模块 结合 Group Conv 和 Channel Shuffle，对ResNet的基础模块bottleneck（下图(a)）进行改进，就得到了 ShuffleNet 的基础模块（下图(b)和(c)）
4.5 ShuffleNet缺点 Channel Shuffle 操作较为耗时，导致 ShuffleNet 的实际运行速度没有那么理想。 Channel Shuffle 的规则是人为制定的，更接近于人工设计特征。

---

文章标题：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices

作者单位：Megvii Inc（Face++）

网络精度：TOP-1 Accuracy 67.4%（1x, g=3）or 67.6%（1x, g=8）

1.1 核心思路
与 MobileNet V1 所提实验结论相类似，ShuffleNet V1 也发现 1x1 卷积将会耗费了大量的计算时间，为此 ShuffleNet V1 提出逐点群卷积来减少计算时间，但逐点群卷积存在不同组间的信息无法进行交互的问题，因此文章还提出通道混洗的操作来帮助信息流通。（ ShuffleNet V1 很多结构设计思想在 ShuffleNet V2 中被推翻，通道混洗操作被保留）

1.2 详解
1. Pointwise Group Convolution（逐点群卷积）

文章发现，诸如 Xception 和 ResNeXt 等 SOTA 的网络基础结构，在小型网络中效率很低，原因在于其中的 1x1 卷积占用了大量的算力资源，对此提出逐点群卷积以减少 1x1 卷积的计算复杂度。这里的逐点群卷积类似于 AlexNet 中的分组卷积，不同的是二者所使用的卷积核大小不同，ShuffleNet V1 使用 1x1 大小的卷积核，而 AlexNet 使用 5x5 或 3x3 大小的卷积核。

2. Channel Shuffle（通道混洗）

在这里插入图片描述

通道混洗的做法：

1）假设输入特征图的通道数为 c ，将通道分为 g 组（组数 g 可以控制逐点卷积的稀疏连接），每组内包含 n 个通道，即 c = g × n c=g×nc=g×n，在通道方向上可重组为一个 g × n g×ng×n 的矩阵；

2）对 g × n g×ng×n 的矩阵进行转置，得到 n × g n×gn×g 的新矩阵；

3）在 n × g n×gn×g 的新矩阵行方向上进行展平操作，以 n 为距离进行重新分组，得到混洗后的输出通道。

3. ShuffleNet V1单元

在这里插入图片描述

文章将 (a) 称作 residual block，ShuffleNet V1 的模块单元便是在 (a) 的基础上将所有的 1x1 卷积替换为逐点群卷积，并在第一个逐点群卷积后进行通道混洗操作，而第二个逐点群卷积后不再进行通道混洗操作（重复且无必要），另外参照 Xception 移除 3x3 深度卷积后的 ReLU 激活函数。卷积步长为 2 时，在 shortcut 路径上增加步长为 2 的平均池化，并将通道间逐元素的相加改为按照通道方向的拼接操作。

4. 网络结构

在这里插入图片描述

在 3 个 stage 中都存在多个重复单元，并且仅在 Stage2 中的第一个逐点群卷积仅进行逐点卷积操作，即不进行分组。

5.ShuffleNet V1的性能表现

下表给出 ShuffleNet V1 取不同组数和缩放比例时的性能表现及相应 FLOPs 。

在这里插入图片描述

其中，ShuffleNet S× 中的 S 代表 filter 数量相较于 ShuffleNet 1× 的比例，所对应的 MFLOPs 也相应变化 S 2 S^2S 
2
 倍。另外，当 g=1 时，ShuffleNet V1 退化为 Xception 的结构。

在相同 FLOPs 下，与其他网络的比较：

在这里插入图片描述

与 MobileNet V1 的比较：

## squeezenet

文章标题：SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size

作者单位：DeepScale；UC Berkeley；Stanford University

数据集：ImageNet

网络精度：TOP-1 Accuracy 57.5%、TOP-5 Accuracy 80.3%（和 AlexNet 差不多），但模型仅为 0.47MB （比 AlexNet 小 510 倍）。【但是这里要注意的是，SqueezeNet 本身的实际模型大小为 4.8MB ，其自身并不具备将模型压缩至 0.47MB 的能力，是因为这里还利用了 Deep Compression 的技术对模型做进一步压缩，有标题党嫌疑】

1.1 核心思路
用1x1卷积替代3x3卷积：1x1卷积比3x3卷积少9倍的参数量；
减少3x3卷积的输入通道数：3×3卷积层的参数量=输入通道数×卷积核层数×(3×3)，所以文章认为不仅需要减少3x3卷积的使用（第一条），在使用3x3卷积时也要减少输入通道数；
后置下采样层位置（3-4个Fire Module之后才接着一个池化层，不同于传统的卷积-池化-卷积-池化…）：文章认为更大的特征图拥有更多的信息（我认为这或许也是精度和模型size之间的一种tradeoff，不可避免地，更大的特征图会让此特征图后的模型参数量和计算量增加，那么达到了增加网络精度的目的，但是同时模型size也跟着变大了）。
简而言之，核心思路第一、第二条主要为了减小模型的size，而第三条主要为了提高模型精度，但同时也增大了模型的size。

1.2 详解
1. Fire Module

在这里插入图片描述
注：上图 squeeze 和 expand 中的 1x1 卷积和 3x3 卷积的数量和比例并不是固定的，可进行调整。

Fire Module 由两部分组成：squeeze 和 expand。

squeeze 部分只包含 1x1 卷积（为什么这么设计？对应核心思路第一条）；

expand 部分既有 1x1 卷积也有 3x3 卷积（前一层的特征图分别经过 1x1卷积和 3x3 卷积，将得到的新特征图按照通道进行拼接[这里借鉴了 Inception ，这里的3x3卷积进行了补零操作，所以整个 Fire Module 过程中的图像分辨率都保持不变，仅是通道数发生了变化）。

在实际使用 Fire Module 时，应该设置 squeeze 的 1x1 卷积个数小于 expand 中的卷积核个数之和（包括 1x1 卷积和 3x3 卷积），以保证 3x3 卷积的输入通道数比较小（对应核心思路第二条）。

2. 网络结构

在这里插入图片描述
注：left to right : SqueezeNet, SqueezeNet with simple bypass, SqueezeNet with complex bypass

其中，上图中间和最右侧结构借鉴了 ResNet 的思想。

其实，SqueezeNet 的架构也是借鉴了 VGG 的形式，对卷积（Fire Module）进行堆叠。这里最后一层的全连接层替换成了全局平均池化，也大大减少了参数量。

---

SqueezeNet 由伯克利&斯坦福的研究人员合作发表于 ICLR-2017，论文标题:

《SqueezeNet：AlexNet-level accuracy with 50x fewer parameters and <0.5MB》

命名：

从名字——SqueezeNet 就知道，本文的新意是 squeeze，squeeze 在 SqueezeNet 中表示一个 squeeze 层，该层采用 1*1 卷积核对上一层 feature map 进行卷积，主要目的是减少 feature map 的维数（维数即通道数，就是一个立方体的 feature map，切成一片一片的，一共有几片）。

创新点：

1. 采用不同于传统的卷积方式，提出 fire module；fire module 包含两部分：squeeze 层+expand 层

创新点与 inception 系列的思想非常接近！首先 squeeze 层，就是 1*1 卷积，其卷积核数要少于上一层 feature map 数，这个操作从 inception 系列开始就有了，并美其名曰压缩，个人觉得「压缩」更为妥当。

Expand 层分别用 1*1 和 3*3 卷积，然后 concat，这个操作在 inception 系列里面也有。

SqueezeNet 的核心在于 Fire module，Fire module 由两层构成，分别是 squeeze 层+expand 层，如下图 1 所示，squeeze 层是一个 1*1 卷积核的卷积层，expand 层是 1*1 和 3*3 卷积核的卷积层，expand 层中，把 1*1 和 3*3 得到的 feature map 进行 concat。



具体操作情况如下图所示：



Fire module 输入的 feature map 为 H*W*M 的，输出的 feature map 为 H*M*(e1+e3)，可以看到 feature map 的分辨率是不变的，变的仅是维数，也就是通道数，这一点和 VGG 的思想一致。

首先，H*W*M 的 feature map 经过 Squeeze 层，得到 S1 个 feature map，这里的 S1 均是小于 M 的，以达到「压缩」的目的，详细思想可参考 Google 的 Inception 系列。

其次，H*W*S1 的特征图输入到 Expand 层，分别经过 1*1 卷积层和 3*3 卷积层进行卷积，再将结果进行 concat，得到 Fire module 的输出，为 H*M*(e1+e3) 的 feature map。

fire 模块有三个可调参数：S1，e1，e3，分别代表卷积核的个数，同时也表示对应输出 feature map 的维数，在文中提出的 SqueezeNet 结构中，e1=e3=4s1。

讲完 SqueezeNet 的核心——Fire module，看看 SqueezeNet 的网络结构，如下图所示：

 



网络结构设计思想，同样与 VGG 的类似，堆叠的使用卷积操作，只不过这里堆叠的使用本文提出的 Fire module（图中用红框部分）。

看看 Squezeenet 的参数数量以及性能：



在这里可以看到，论文题目中提到的小于 0.5M，是采用了 Deep Compression 进行模型压缩之后的结果！！

看了上图再回头看一看论文题目： 

SqueezeNet ：AlexNet-level accuracy with 50x fewer parameters and <0.5MB

标！题！党！SqueezeNet < 0.5MB, 这个是用了别的模型压缩技术获得的，很容易让人误以为 SqueezeNet 可以压缩模型！！ 

SqueezeNet 小结：

1 Fire module 与 GoogLeNet 思想类似，采用 1*1 卷积对 feature map 的维数进行「压缩」，从而达到减少权值参数的目的；
2 采用与 VGG 类似的思想——堆叠的使用卷积，这里堆叠的使用 Fire module
SqueezeNet 与 GoogLeNet 和 VGG 的关系很大！

---

  SqueezeNet相比于传统的卷积神经网络使得网络模型在参数量和计算量上都比较小，同时保持较高的准确率。更适合在资源受限的设备上进行部署。

  SqueezeNet的设计思路主要有两个关键点：

采用了1×1卷积核来降低网络的参数量和计算量；
采用了“squeeze-and-excitation”模块来提高网络的表示能力。
  具体来说，SqueezeNet中的大多数卷积层都采用了1×1卷积核，这种卷积核的参数量较少，可以在不增加计算量的前提下降低网络的参数量。而“squeeze-and-excitation”模块则通过对不同通道的特征进行压缩和激励，进一步提高了网络的表示能力。

---

轻量化网络中一个著名的网络是 SqueezeNet ，它发表于ICLR 2017，它拥有与 AlexNet 相同的精度，但只用了 AlexNet 1/50 的参数量。 SqueezeNet 的核心在于采用不同于常规的卷积方式来降低参数量，具体做法是使用 Fire Module，先用 1 × 1 卷积降低通道数目，然后用 1 × 1 卷积和 3 × 3 卷积提升通道数。

2.1 压缩策略 SqueezeNet 采用如下3个策略： ① 将 3 × 3 卷积替换为 1 × 1 卷积 ② 减少 3 × 3 卷积的通道数 ③ 将降采样操作延后，这样可以给卷积提供更大的 activation map，从而保留更多的信息，提供更高的分类准确率。 其中，策略1和2可以显著减少模型参数量，策略3可以在模型参数量受限的情况下提高模型的性能。

2.2 Fire Module
Fire Module是SqueezeNet网络的基础模块，设计如下图所示：

一个 Fire Module 由 Squeeze 和 Extract 两部分组成： Squeeze 部分包括了一系列连续的 1 × 1 卷积 Extract 部分包括了一系列连续的 1 × 1 卷积和一系列连续的 3 × 3 卷积，然后将 1 × 1 和 3 × 3 的卷积结果进行concat。 记 Squeeze 部分的通道数为 C s 1 × 1 ，Extract部分 1 × 1 和 3 × 3 的通道数分别为 C e 1 × 1 和 C e 3 × 3 ，作者建议 C s 1 × 1 < C e 1 × 1 + C e 3 × 3 ，这样做相当于在 Squeeze 和 Extraxt 之间插入了 bottlenet。

2.3 网络结构 在Fire Module的基础上搭建SqueezeNet神经网络。它以卷积层开始，后面是 8 个 Fire Module，最后以卷积层结束，每个 Fire Module 中的通道数目逐渐增加。另外网络在 conv1，fire4，fire8，conv10的后面使用了 max-pooling。 SqueezeNet 结构如下图所示，左侧是不加 shortcut 的版本，中间是加了 shortcut 的版本，右侧是在不同通道的特征图之间加入 shortcut 的版本。

SqueezeNet的性能类似于AlenNet，然而参数量只有后者的1/50，使用Deep Compression可以进一步将模型大小压缩到仅仅有0.5M。

2.4 SqueezeNet缺点 SqueezeNet 缺点如下： SqueezeNet 通过更深的网络置换更多的参数，虽然有更低的参数量，但是网络的测试阶段耗时会增加，考虑到轻量级模型倾向于应用在嵌入式场景，这一变化可能会带来新的问题。 AlaxNet 的参数量(50M)大部分由全连接层带来，加上一部分参数量进行对比，数字稍有夸张。
